{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive Bayes .ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O82Dav-fbVw-"
      },
      "source": [
        "# **Naive Bayes From Scratch**\r\n",
        "\r\n",
        "### **Step 1: Handle Data** \r\n",
        "The first thing we need to do is load our data file. The data is in CSV format without a header line or any quotes. We can open the file with the open function and read the data lines using the reader function in the CSV module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7JSDHBGbPKn"
      },
      "source": [
        "import csv\r\n",
        "import math\r\n",
        "import random\r\n",
        " \r\n",
        " \r\n",
        "def loadCsv(filename):\r\n",
        "  lines = csv.reader(open(r'pima-indians-diabetes.csv'))\r\n",
        "  dataset = list(lines)\r\n",
        "  for i in range(len(dataset)):\r\n",
        "    dataset[i] = [float(x) for x in dataset[i]]\r\n",
        "  return dataset"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYuLVTwicVyg"
      },
      "source": [
        "# Split the data into training and testing dataset.\r\n",
        "def splitDataset(dataset, splitRatio):\r\n",
        "  trainSize = int(len(dataset) * splitRatio)\r\n",
        "  trainSet = []\r\n",
        "  copy = list(dataset)\r\n",
        "  while len(trainSet) < trainSize:\r\n",
        "    index = random.randrange(len(copy))\r\n",
        "    trainSet.append(copy.pop(index))\r\n",
        "  return [trainSet, copy]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvwX9A_xgAeH"
      },
      "source": [
        "### **Step 2: Summarize the Data**\r\n",
        "The summary of the training data collected involves the mean and the standard deviation for each attribute, by class value. These are required when making predictions to calculate the probability of specific attribute values belonging to each class value.\r\n",
        "\r\n",
        "We can break the preparation of this summary data down into the following sub-tasks:\r\n",
        "\r\n",
        "* **Separate Data By Class**\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9txzqvyd-da"
      },
      "source": [
        "def separateByClass(dataset):\r\n",
        "  separated = {}\r\n",
        "  for i in range(len(dataset)):\r\n",
        "    vector = dataset[i]\r\n",
        "    if (vector[-1] not in separated):\r\n",
        "      separated[vector[-1]] = []\r\n",
        "    separated[vector[-1]].append(vector)\r\n",
        "  return separated"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXY_a1p1g6Gk"
      },
      "source": [
        "* **Calculate Mean**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iksfg6CMguE-"
      },
      "source": [
        "def mean(numbers):\r\n",
        "  return sum(numbers)/float(len(numbers))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcgusNYSih29"
      },
      "source": [
        "* **Calculate Standard Deviation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lacUgnBQioGn"
      },
      "source": [
        "def stdev(numbers):\r\n",
        "  avg = mean(numbers)\r\n",
        "  variance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\r\n",
        "  return math.sqrt(variance)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ppN6J2NitIe"
      },
      "source": [
        "* **Summarize Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuVNbovNir5b"
      },
      "source": [
        "def summarize(dataset):\r\n",
        "  summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\r\n",
        "  del summaries[-1]\r\n",
        "  return summaries"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQFw_rRwi9IJ"
      },
      "source": [
        "* **Summarize Attributes By Class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7mqsxu8i4FX"
      },
      "source": [
        "def summarizeByClass(dataset):\r\n",
        "  separated = separateByClass(dataset)\r\n",
        "  summaries = {}\r\n",
        "  for classValue, instances in separated.items():\r\n",
        "    summaries[classValue] = summarize(instances)\r\n",
        "  return summaries"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BzRMm-HjFTT"
      },
      "source": [
        "### **Step 3: Making Predictions**\r\n",
        "We are now ready to make predictions using the summaries prepared from our training data. Making predictions involves calculating the probability that a given data instance belongs to each class, then selecting the class with the largest probability as the prediction. We need to perform the following tasks:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iojLDM3UjEem"
      },
      "source": [
        "# Calculate Gaussian Probability Density Function\r\n",
        "\r\n",
        "def calculateProbability(x, mean, stdev):\r\n",
        "  exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\r\n",
        "  return (1/(math.sqrt(2*math.pi)*stdev))*exponent"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d05P9XfUjbxK"
      },
      "source": [
        "# Calculate Class Probabilities\r\n",
        "\r\n",
        "def calculateClassProbabilities(summaries, inputVector):\r\n",
        "  probabilities = {}\r\n",
        "  for classValue, classSummaries in summaries.items():\r\n",
        "    probabilities[classValue] = 1\r\n",
        "    for i in range(len(classSummaries)):\r\n",
        "      mean, stdev = classSummaries[i]\r\n",
        "      x = inputVector[i]\r\n",
        "      probabilities[classValue] *= calculateProbability(x, mean, stdev)\r\n",
        "    return probabilities"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MajZASYtkPkc"
      },
      "source": [
        "# Make a Prediction\r\n",
        "\r\n",
        "def predict(summaries, inputVector):\r\n",
        "  probabilities = calculateClassProbabilities(summaries, inputVector)\r\n",
        "  bestLabel, bestProb = None, -1\r\n",
        "  for classValue, probability in probabilities.items():\r\n",
        "    if bestLabel is None or probability > bestProb:\r\n",
        "      bestProb = probability\r\n",
        "      bestLabel = classValue\r\n",
        "  return bestLabel"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqYO3RizkjDT"
      },
      "source": [
        "# Make Predictions\r\n",
        "\r\n",
        "def getPredictions(summaries, testSet):\r\n",
        "  predictions = []\r\n",
        "  for i in range(len(testSet)):\r\n",
        "    result = predict(summaries, testSet[i])\r\n",
        "    predictions.append(result)\r\n",
        "  return predictions"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6So19DTkxNS"
      },
      "source": [
        "# Get Accuracy\r\n",
        "\r\n",
        "def getAccuracy(testSet, predictions):\r\n",
        "  correct = 0\r\n",
        "  for x in range(len(testSet)):\r\n",
        "    if testSet[x][-1] == predictions[x]:\r\n",
        "      correct += 1\r\n",
        "  return (correct/float(len(testSet)))*100.0"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdomfSOKk7Jf"
      },
      "source": [
        "Finally, we define our main function where we call all these methods we have defined, one by one to get the accuracy of the model we have created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32Pr3E4ok3lD",
        "outputId": "b564842c-c17c-4af2-d24c-517b2881ca26"
      },
      "source": [
        "def main():\r\n",
        "  filename = 'pima-indians-diabetes.data.csv'\r\n",
        "  splitRatio = 0.67\r\n",
        "  dataset = loadCsv(filename)\r\n",
        "  trainingSet, testSet = splitDataset(dataset, splitRatio)\r\n",
        "  print('Split {0} rows into train = {1} and test = {2} rows'.format(len(dataset),len(trainingSet),len(testSet)))\r\n",
        "  #prepare model\r\n",
        "  summaries = summarizeByClass(trainingSet)\r\n",
        "  #test model\r\n",
        "  predictions = getPredictions(summaries, testSet)\r\n",
        "  accuracy = getAccuracy(testSet, predictions)\r\n",
        "  print('Accuracy: {0}%'.format(accuracy))\r\n",
        " \r\n",
        "main()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Split 768 rows into train = 514 and test = 254 rows\n",
            "Accuracy: 68.11023622047244%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YntvqCQplFFA"
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": []
    }
  ]
}